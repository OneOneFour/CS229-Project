{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import xarray \n",
    "import numpy as np\n",
    "ds = util.get_dataset()\n",
    "sst_ds = xarray.open_dataset(\"../data/sst.wkmean.1990-present.nc\")\n",
    "sst_ds = sst_ds.assign_coords(lon=(((sst_ds.lon + 180) % 360) - 180)) ## Use consistent longitude\n",
    "train_storms,valid_storms,test_storms = util.train_validation_test(ds,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def coriolis_parameter(lat):\n",
    "    return 2*np.sin(np.deg2rad(lat))\n",
    "\n",
    "def make_X_y(ds,selected_storms,timesteps=5):\n",
    "    Xout = []\n",
    "    yout =[]\n",
    "    storms = []\n",
    "    for stormidx,storm in enumerate(selected_storms):\n",
    "        usa_pres = ds.usa_pres.loc[storm]\n",
    "        usa_wind = ds.usa_wind.loc[storm]\n",
    "        ## All enteries have 360 points.\n",
    "        valid_coords = ~(np.isnan(usa_wind) | np.isnan(usa_pres))\n",
    "        lat = ds.lat.loc[storm][valid_coords]\n",
    "        lon = ds.lon.loc[storm][valid_coords]\n",
    "        storm_speed = ds.storm_speed.loc[storm][valid_coords]\n",
    "        storm_dir = ds.storm_dir.loc[storm][valid_coords]\n",
    "        usa_pres = usa_pres[valid_coords]\n",
    "        usa_wind = usa_wind[valid_coords]\n",
    "        time = ds.time.loc[storm][valid_coords]\n",
    "        cor_param = coriolis_parameter(lat)\n",
    "        try:\n",
    "            sst = sst_ds.sst.interp(time=time,lat=lat,lon=lon)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if np.isnan(sst).any():\n",
    "            continue\n",
    "\n",
    "        X = np.transpose(np.array([usa_wind,usa_pres,storm_speed,storm_dir,cor_param,sst,lat,lon]))\n",
    "        for i in range(0,len(usa_wind)):\n",
    "            if i+timesteps+1>=len(usa_wind):\n",
    "                break\n",
    "            Xout.append(X[i:i+timesteps])\n",
    "            yout.append(X[i+timesteps+1][:-4])\n",
    "            storms.append(stormidx)\n",
    "    return np.stack(Xout),np.stack(yout),np.array(storms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEPOINTS = 10\n",
    "x_train,y_train,storm_train = make_X_y(ds,train_storms,TIMEPOINTS)\n",
    "x_valid,y_valid,storm_valid = make_X_y(ds,valid_storms,TIMEPOINTS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=150, n_jobs=-1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=150,n_jobs=-1)\n",
    "rf.fit(x_train.reshape((x_train.shape[0],-1)),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_valid = rf.predict(x_valid.reshape((x_valid.shape[0],-1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.55696218,  4.34667666,  3.32375799, 55.78284987])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_valid,pred_valid,multioutput='raw_values',squared=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross validation train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-18.00820017, -18.80518828, -18.07674251, -17.92560441,\n",
       "       -18.38403479])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold,cross_val_score\n",
    "cv = GroupKFold(n_splits=5)\n",
    "cross_val_score(rf,x_train.reshape((x_train.shape[0],-1)),y_train,groups=storm_train,cv=cv,scoring='neg_root_mean_squared_error',n_jobs=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on full test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "732e0b614408a87036c6c94cd8c4a28ec9f4a21fcd18cd6fea5bab582ca55e9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
